// heuristic_dim_lambda.cpp
// Implements a heuristic search for partitions maximizing f^lambda (SYT count),
// with an added "shaking" step for candidate generation.
// Heuristic: Search within the subgraph G'. Candidates for n+1 include those
//            generated by adding one box (k=0), PLUS those generated by "shaking"
//            with exactly k remove/add steps for each k=1,2,...,MAX_SHAKE_K,
//            evaluating the best dim at each k and comparing. All candidates
//            must remain within G'.
/*
COMPILE:

clang++ -O3 -march=native -flto -fuse-linker-plugin -funroll-loops -ftree-vectorize -pthread -ffast-math -fopenmp -o heuristic_dim_lambda heuristic_dim_lambda.cpp -lgmp -lgmpxx -I/opt/homebrew/include -L/opt/homebrew/lib

USAGE:

./heuristic_dim_lambda <N> [--shake=k] [--stop-window=L] [--recompute=size] [--store-n=M] [--store-n1=K]

Parameters:
  <N>             : Perform heuristic search up to size N
  --shake=k       : Set the maximum exact shake parameter (default: 8)
  --stop-window=L : Set the window length for early stopping (default: 3)
  --recompute=size: Force recomputation for specific size
  --store-n=M     : Maximum number of top partitions to keep in the pool for size n (default: 100)
  --store-n1=K    : Maximum number of top partitions to keep in the pool for size n-1 (default: 50)
  --store-max=M   : (Legacy) Sets both pool sizes (--store-n=M and --store-n1=M/2)
*/

#include <iostream>
#include <vector>
#include <string>
#include <numeric>
#include <algorithm>
#include <fstream>
#include <sstream>
#include <stdexcept>
#include <set>       // To store unique candidate partitions efficiently
#include <map>       // For checking G' constraints & potentially caching
#include <iomanip>   // For formatting output
#include <cmath>     // For floor
#include <queue>     // Might be useful for shaking implementation if needed
#include <omp.h>     // For OpenMP parallelization
#include <mutex>     // For thread-safe caching
#include <chrono>    // For getting current time
#include <ctime>     // For time formatting

// Include GMP C++ interface header
#include <gmpxx.h>

// --- Configuration & Type Aliases ---
using std::vector;
using std::cout;
using std::cerr;
using std::endl;
using std::string;
using std::max;
using std::min;

// Type alias for Partition (using unsigned int for parts)
using Partition = vector<unsigned int>;
// Use a set to store partitions to automatically handle uniqueness and ordering
using PartitionSet = std::set<Partition>;

// GMP Integer type alias
using BigInt = mpz_class;

// Type alias for storing a partition along with its score (f^lambda)
using ScoredPartition = std::pair<BigInt, Partition>;

// --- Function Declarations ---

// Helper to convert partition to string
string partition_to_string(const Partition& p);

// Generate partitions of size |mu|+1 by adding one box to mu
vector<Partition> add_box(const Partition& mu);

// Generate partitions of size |mu|+2 by adding two boxes
PartitionSet add_two_boxes(const Partition& p_n_minus_1);

// Generate partitions of size |lambda|-1 by removing one outer corner box
vector<Partition> remove_box(const Partition& lambda);

// Generate additional candidates by "shaking" (exactly k remove/add steps)
PartitionSet generate_shaken_candidates(const Partition& lambda_start, int exact_k);

// Check if a partition is valid (parts are non-increasing and positive)
bool is_valid_partition(const Partition& p);

// Check if a partition belongs to the subgraph G' defined in a.pdf
bool is_in_subgraph_G_prime(const Partition& p);

// Clear cache for is_in_subgraph_G_prime to prevent memory growth
void clear_g_prime_cache();

// Find the largest symmetric subdiagram (base subdiagram) lambda_sym
Partition get_base_symmetric_subdiagram(const Partition& p);

// Hook Length Calculation
long long hookLength(const Partition& partition, int r, int c);

// Standard Young Tableaux (SYT) Count Calculation (GMP Integer version)
BigInt countSYT_gmp(const Partition& partition);

// Function to parse a partition string in format [n1, n2, ..., nk]
Partition parse_partition(const string& partition_str) {
    Partition result;
    if (partition_str.empty() || partition_str == "[]") return result;

    // Remove [] and split by commas
    string inner = partition_str.substr(1, partition_str.size() - 2);
    std::stringstream ss(inner);
    string part_str;
    while (std::getline(ss, part_str, ',')) {
        // Trim whitespace
        part_str.erase(0, part_str.find_first_not_of(" \t"));
        part_str.erase(part_str.find_last_not_of(" \t") + 1);
        if (!part_str.empty()) {
            try {
                unsigned int part = std::stoi(part_str);
                result.push_back(part);
            } catch (const std::exception& e) {
                cerr << "Error parsing partition part: " << part_str << endl;
            }
        }
    }
    return result;
}

// Function to parse heuristic_results.txt and extract previous results
bool read_previous_results(std::vector<std::pair<int, BigInt>>& mathematica_data,
                          std::vector<std::pair<int, std::vector<Partition>>>& size_to_partitions,
                          int& max_n_found) {
    std::ifstream infile("heuristic_results.txt");
    if (!infile) {
        return false; // File doesn't exist or can't be opened
    }

    cout << "Found existing results file. Reading previous results..." << endl;

    string line;
    int current_size = 0;
    BigInt current_max_f = 0;
    std::vector<Partition> current_partitions;
    max_n_found = 0;

    // Skip header lines
    for (int i = 0; i < 2; i++) {
        if (!std::getline(infile, line)) {
            return false; // Unexpected end of file
        }
    }

    while (std::getline(infile, line)) {
        if (line.empty()) continue;

        // Check for size marker
        if (line.find("--- Size ") != string::npos) {
            // If we have data from a previous size, save it before moving on
            if (current_size > 0 && current_max_f > 0) {
                mathematica_data.push_back({current_size, current_max_f});
                size_to_partitions.push_back({current_size, current_partitions});
                max_n_found = std::max(max_n_found, current_size);
            }

            // Extract new size
            size_t pos = line.find("Size ") + 5;
            size_t end_pos = line.find(" ---", pos);
            if (end_pos != string::npos) {
                string size_str = line.substr(pos, end_pos - pos);
                current_size = std::stoi(size_str);
                current_partitions.clear();
                current_max_f = 0;
            }
        }
        // Check for max f^lambda line
        else if (line.find("Max f^lambda: ") != string::npos) {
            if (line.find("N/A") != string::npos) {
                current_max_f = 0; // No valid candidates found
                continue;
            }

            size_t pos = line.find("Max f^lambda: ") + 13;
            size_t end_pos = line.find(" (", pos);
            if (end_pos != string::npos) {
                string max_f_str = line.substr(pos, end_pos - pos);
                current_max_f = BigInt(max_f_str);
            }
        }
        // Check for partitions line
        else if (line.find("Partitions achieving maximum: ") != string::npos) {
            size_t pos = line.find("maximum: ") + 9;
            string partitions_str = line.substr(pos);

            // Split by commas (outside of brackets)
            current_partitions.clear();
            string current_partition;
            int bracket_depth = 0;

            for (char c : partitions_str) {
                if (c == '[') bracket_depth++;
                else if (c == ']') bracket_depth--;

                if (c == ',' && bracket_depth == 0) {
                    // End of a partition
                    current_partition.erase(0, current_partition.find_first_not_of(" \t"));
                    current_partition.erase(current_partition.find_last_not_of(" \t") + 1);
                    if (!current_partition.empty()) {
                        Partition p = parse_partition(current_partition);
                        if (!p.empty()) {
                            current_partitions.push_back(p);
                        }
                    }
                    current_partition.clear();
                } else {
                    current_partition += c;
                }
            }

            // Don't forget the last partition
            if (!current_partition.empty()) {
                current_partition.erase(0, current_partition.find_first_not_of(" \t"));
                current_partition.erase(current_partition.find_last_not_of(" \t") + 1);
                Partition p = parse_partition(current_partition);
                if (!p.empty()) {
                    current_partitions.push_back(p);
                }
            }
        }
    }

    // Don't forget to add the last size we processed
    if (current_size > 0 && current_max_f > 0) {
        mathematica_data.push_back({current_size, current_max_f});
        size_to_partitions.push_back({current_size, current_partitions});
        max_n_found = std::max(max_n_found, current_size);
    }

    cout << "Successfully read results for sizes 1 to " << max_n_found << endl;
    return true;
}

// --- Main Function ---

int main(int argc, char* argv[]) {
    // Parse command line arguments
    if (argc < 2) {
        cerr << "Usage: " << argv[0] << " <N> [--shake=k] [--stop-window=L] [--recompute=size] [--store-n=M] [--store-n1=K]" << endl;
        cerr << "Parameters:" << endl;
        cerr << "  <N>             : Perform heuristic search up to size N" << endl;
        cerr << "  --shake=k       : Set the maximum exact shake parameter (default: 8)" << endl;
        cerr << "  --stop-window=L : Set the window length for early stopping (default: 3)" << endl;
        cerr << "  --recompute=size: Force recomputation for specific size" << endl;
        cerr << "  --store-n=M     : Maximum number of top partitions to keep in the pool for size n (default: 100)" << endl;
        cerr << "  --store-n1=K    : Maximum number of top partitions to keep in the pool for size n-1 (default: 50)" << endl;
        cerr << "  --store-max=M   : (Legacy) Sets both pool sizes (--store-n=M and --store-n1=M/2)" << endl;
        cerr << "Performs a heuristic search for partitions" << endl;
        cerr << "maximizing f^lambda up to size N, starting from n=1." << endl;
        cerr << "Results are written to heuristic_results.txt and output in Mathematica format" << endl;
        return 1;
    }

    int N;
    try {
        N = std::stoi(argv[1]);
        if (N <= 0) {
            throw std::invalid_argument("N must be a positive integer.");
        }
    } catch (const std::exception& e) {
        cerr << "Error: Invalid input for N. Please provide a positive integer." << endl;
        cerr << e.what() << endl;
        return 1;
    }

    int MAX_SHAKE_K = 1; // Default max remove/add steps for shaking
    int EARLY_STOP_WINDOW = 10; // Default window length for early stopping (3 means look at j,j+1,j+2)
    int recompute_size = -1; // Default: no recomputation
    // Replace single pool size with two separate pool sizes
    const int STORED_MAX_PARTITIONS_N = 600; // Max partitions in the pool for size n (used to generate n+1)
    const int STORED_MAX_PARTITIONS_N_MINUS_1 = 20; // Max partitions in the pool for size n-1 (used to generate n+1)
    // precise_mode is always true by default

    // Parse optional command line arguments
    for (int i = 2; i < argc; i++) {
        string arg = argv[i];

        // Parse shake parameter
        if (arg.substr(0, 8) == "--shake=") {
            try {
                MAX_SHAKE_K = std::stoi(arg.substr(8));
                if (MAX_SHAKE_K < 0) {
                    cerr << "Warning: shake parameter must be non-negative. Using default value 3." << endl;
                    MAX_SHAKE_K = 3;
                }
                cout << "Using maximum shake parameter: " << MAX_SHAKE_K << endl;
            } catch (const std::exception& e) {
                cerr << "Warning: Invalid shake parameter. Using default value 3." << endl;
            }
        }

        // Parse early stop window parameter
        else if (arg.substr(0, 14) == "--stop-window=") {
            try {
                EARLY_STOP_WINDOW = std::stoi(arg.substr(14));
                if (EARLY_STOP_WINDOW < 2) {
                    cerr << "Warning: Early stop window must be at least 2. Using default value 3." << endl;
                    EARLY_STOP_WINDOW = 3;
                }
                cout << "Using early stopping window: " << EARLY_STOP_WINDOW << endl;
            } catch (const std::exception& e) {
                cerr << "Warning: Invalid early stop window parameter. Using default value 3." << endl;
            }
        }

        // Parse recompute parameter
        else if (arg.substr(0, 12) == "--recompute=") {
            try {
                recompute_size = std::stoi(arg.substr(12));
                if (recompute_size <= 0 || recompute_size > N) {
                    cerr << "Warning: recompute size must be a positive integer <= N. Ignoring." << endl;
                    recompute_size = -1;
                } else {
                    cout << "Will force recomputation for size: " << recompute_size << endl;
                }
            } catch (const std::exception& e) {
                cerr << "Warning: Invalid recompute parameter. Ignoring." << endl;
            }
        }

        // Parse store-n parameter (replaces --store-max)
        else if (arg.substr(0, 10) == "--store-n=") {
            try {
                int store_n = std::stoi(arg.substr(10));
                if (store_n < 1) {
                    cerr << "Warning: store-n parameter must be at least 1. Using default value 100." << endl;
                } else {
                    const_cast<int&>(STORED_MAX_PARTITIONS_N) = store_n;
                    cout << "Using maximum stored partitions for size n: " << STORED_MAX_PARTITIONS_N << endl;
                }
            } catch (const std::exception& e) {
                cerr << "Warning: Invalid store-n parameter. Using default value 100." << endl;
            }
        }
        // Parse store-n1 parameter
        else if (arg.substr(0, 11) == "--store-n1=") {
            try {
                int store_n1 = std::stoi(arg.substr(11));
                if (store_n1 < 1) {
                    cerr << "Warning: store-n1 parameter must be at least 1. Using default value 50." << endl;
                } else {
                    const_cast<int&>(STORED_MAX_PARTITIONS_N_MINUS_1) = store_n1;
                    cout << "Using maximum stored partitions for size n-1: " << STORED_MAX_PARTITIONS_N_MINUS_1 << endl;
                }
            } catch (const std::exception& e) {
                cerr << "Warning: Invalid store-n1 parameter. Using default value 50." << endl;
            }
        }
        // Support legacy store-max parameter for backward compatibility
        else if (arg.substr(0, 12) == "--store-max=") {
            try {
                int store_max = std::stoi(arg.substr(12));
                if (store_max < 1) {
                    cerr << "Warning: store-max parameter must be at least 1. Using default values." << endl;
                } else {
                    const_cast<int&>(STORED_MAX_PARTITIONS_N) = store_max;
                    const_cast<int&>(STORED_MAX_PARTITIONS_N_MINUS_1) = store_max / 2; // Set n-1 pool to half the size by default
                    cout << "Legacy parameter: Using maximum stored partitions for size n: " << STORED_MAX_PARTITIONS_N
                         << " and for size n-1: " << STORED_MAX_PARTITIONS_N_MINUS_1 << endl;
                }
            } catch (const std::exception& e) {
                cerr << "Warning: Invalid store-max parameter. Using default values." << endl;
            }
        }

        // Unknown parameter
        else {
            cerr << "Warning: Unknown parameter '" << arg << "' ignored." << endl;
        }
    }

    // Mathematica format data storage
    std::vector<std::pair<int, BigInt>> mathematica_data;
    std::vector<std::pair<int, std::vector<Partition>>> size_to_partitions;

    // Check if results file exists and try to read previous results
    int max_n_found = 0;
    bool has_previous_results = read_previous_results(mathematica_data, size_to_partitions, max_n_found);

    // Handle recomputation options
    if (has_previous_results) {
        if (recompute_size > 0) {
            cout << "Forcing recomputation for size " << recompute_size << endl;

            // Remove the data for the specified size from the loaded data
            for (auto it = mathematica_data.begin(); it != mathematica_data.end(); ) {
                if (it->first == recompute_size) {
                    it = mathematica_data.erase(it);
                } else {
                    ++it;
                }
            }

            for (auto it = size_to_partitions.begin(); it != size_to_partitions.end(); ) {
                if (it->first == recompute_size) {
                    it = size_to_partitions.erase(it);
                } else {
                    ++it;
                }
            }

            // If this was the max size, update max_n_found
            if (recompute_size == max_n_found) {
                // Find the new maximum size
                max_n_found = 0;
                for (const auto& pair : mathematica_data) {
                    if (pair.first > max_n_found) {
                        max_n_found = pair.first;
                    }
                }
            }

            cout << "Removed data for size " << recompute_size << ". Will recalculate." << endl;
        }
    }

    // If we already have all the data we need and no recomputation is needed, just print the Mathematica output and exit
    if (has_previous_results && max_n_found >= N && recompute_size < 0) {
        cout << "Already have results up to n = " << max_n_found << " (>= requested N = " << N << ")" << endl;
        cout << "Using existing results from heuristic_results.txt" << endl;

        // Print Mathematica format output up to requested N
        cout << "\nMathematica format output:" << endl;
        cout << "MM := {";
        for (size_t i = 0; i < mathematica_data.size() && mathematica_data[i].first <= N; ++i) {
            cout << "{" << mathematica_data[i].first << ", " << mathematica_data[i].second << "}";
            if (i < mathematica_data.size() - 1 && mathematica_data[i+1].first <= N) {
                cout << ", ";
            }
        }
        cout << "}" << endl;

        // Force update of heuristic_results.txt with shake parameter
        if (recompute_size > 0) {
            cout << "Forcing update of heuristic_results.txt with shake parameter = " << MAX_SHAKE_K << endl;
        }
        else {
            return 0;
        }
    }

    cout << "Starting heuristic search (with incremental shake, early stop window = " << EARLY_STOP_WINDOW
         << ", stored partitions n = " << STORED_MAX_PARTITIONS_N
         << ", stored partitions n-1 = " << STORED_MAX_PARTITIONS_N_MINUS_1
         << ") for max f^lambda up to n = " << N << endl;

    // Initialize from previous results or start fresh
    vector<Partition> overall_best_partitions_for_n; // Stores partition(s) with the absolute max f^lambda for size n
    std::vector<ScoredPartition> pool_n; // Pool of top partitions for current size n
    std::vector<ScoredPartition> pool_n_minus_1; // Pool of top partitions for previous size n-1
    BigInt current_max_f_lambda = 0;
    int start_n = 1;

    // --- File Output Setup ---
    std::ofstream outfile;
    if (has_previous_results) {
        // Determine the start_n based on recompute_size
        if (recompute_size > 0) {
            // We need to start from the size before the one we want to recompute
            // (or from 1 if recomputing size 1 or 2)
            start_n = (recompute_size <= 2) ? 1 : (recompute_size - 1);

            // Find the data for the starting size
            bool found_start_data = false;
            for (size_t i = 0; i < size_to_partitions.size(); i++) {
                if (size_to_partitions[i].first == start_n) {
                    overall_best_partitions_for_n = size_to_partitions[i].second;
                    found_start_data = true;

                    // Find corresponding max_f_lambda
                    for (const auto& data : mathematica_data) {
                        if (data.first == start_n) {
                            current_max_f_lambda = data.second;
                            break;
                        }
                    }
                    break;
                }
            }

            if (!found_start_data && start_n > 1) {
                cerr << "Error: Could not find data for size " << start_n << " needed to recompute size " << recompute_size << "." << endl;
                return 1;
            }

            // Initialize pool_n using overall_best_partitions_for_n
            pool_n.clear();
            for (const auto& p : overall_best_partitions_for_n) {
                pool_n.push_back({current_max_f_lambda, p});
            }

            // Initialize pool_n_minus_1 if possible
            if (start_n > 1) {
                // Try to find data for n-1
                bool found_n_minus_1 = false;
                for (size_t i = 0; i < size_to_partitions.size(); i++) {
                    if (size_to_partitions[i].first == start_n - 1) {
                        found_n_minus_1 = true;
                        pool_n_minus_1.clear();
                        BigInt n_minus_1_score = 0;

                        // Find corresponding max_f_lambda for n-1
                        for (const auto& data : mathematica_data) {
                            if (data.first == start_n - 1) {
                                n_minus_1_score = data.second;
                                break;
                            }
                        }

                        // Initialize pool
                        for (const auto& p : size_to_partitions[i].second) {
                            pool_n_minus_1.push_back({n_minus_1_score, p});
                        }
                        break;
                    }
                }

                if (!found_n_minus_1) {
                    cout << "Note: Could not find data for size " << start_n - 1 << ". Will not use n-1 source for first iteration." << endl;
                }
            }

            cout << "Will recompute from size " << start_n << " to get size " << recompute_size << endl;
        } else {
            cout << "Continuing from last found size n = " << max_n_found << endl;

            // Set starting point from previous results (standard behavior)
            if (!size_to_partitions.empty()) {
                auto last_result = size_to_partitions.back();
                if (last_result.first == max_n_found) {
                    start_n = max_n_found;
                    overall_best_partitions_for_n = last_result.second;

                    // Find corresponding max_f_lambda
                    for (const auto& data : mathematica_data) {
                        if (data.first == max_n_found) {
                            current_max_f_lambda = data.second;
                            break;
                        }
                    }

                    // Initialize pool_n using overall_best_partitions_for_n
                    pool_n.clear();
                    for (const auto& p : overall_best_partitions_for_n) {
                        pool_n.push_back({current_max_f_lambda, p});
                    }

                    // Initialize pool_n_minus_1 if possible
                    if (max_n_found > 1) {
                        // Try to find data for n-1
                        bool found_n_minus_1 = false;
                        for (size_t i = 0; i < size_to_partitions.size(); i++) {
                            if (size_to_partitions[i].first == max_n_found - 1) {
                                found_n_minus_1 = true;
                                pool_n_minus_1.clear();
                                BigInt n_minus_1_score = 0;

                                // Find corresponding max_f_lambda for n-1
                                for (const auto& data : mathematica_data) {
                                    if (data.first == max_n_found - 1) {
                                        n_minus_1_score = data.second;
                                        break;
                                    }
                                }

                                // Initialize pool
                                for (const auto& p : size_to_partitions[i].second) {
                                    pool_n_minus_1.push_back({n_minus_1_score, p});
                                }
                                break;
                            }
                        }

                        if (!found_n_minus_1) {
                            cout << "Note: Could not find data for size " << max_n_found - 1 << ". Will not use n-1 source for first iteration." << endl;
                        }
                    }
                }
            }
        }

        // For recompute-specific-size, we'll keep all data in memory for now,
        // but not write to the file yet - we'll only update the file after recalculating
        if (recompute_size > 0) {
            // Only close outfile - we'll rewrite the file contents at the end
            outfile.close();
            cout << "Will retain existing data and update only size " << recompute_size << " after recalculation" << endl;
        } else {
            // Standard behavior - append to existing file
            outfile.open("heuristic_results.txt", std::ios_base::app);
            if (!outfile) {
                cerr << "Error: Could not open file heuristic_results.txt for appending." << endl;
                return 1;
            }
        }
    } else {
        // Create new file if no previous results
        // Create new file
        outfile.open("heuristic_results.txt");
        if (!outfile) {
            cerr << "Error: Could not open file heuristic_results.txt for writing." << endl;
            return 1;
        }
        outfile << "Heuristic search results (with optimal shake, early stop window = " << EARLY_STOP_WINDOW
                << ", stored partitions n = " << STORED_MAX_PARTITIONS_N
                << ", stored partitions n-1 = " << STORED_MAX_PARTITIONS_N_MINUS_1
                << ") for partitions maximizing f^lambda (SYT count)\n";
        outfile << "-------------------------------------------------------------------------------------------------------------------\n";

        // Base case n=1
        if (N >= 1) {
            Partition p1 = {1};
            if (!is_in_subgraph_G_prime(p1)) {
                cerr << "Error: Base partition [1] does not satisfy G' constraints. Exiting." << endl;
                return 1;
            }
            overall_best_partitions_for_n.push_back(p1);
            current_max_f_lambda = 1;

            // Add to the new pool
            pool_n.push_back({current_max_f_lambda, p1});

            outfile << "--- Size 1 ---" << endl;
            outfile << "Max f^lambda: " << current_max_f_lambda << " (achieved by 1 partition)" << endl;
            outfile << "Partitions achieving maximum: " << partition_to_string(p1) << endl;

            // Store for Mathematica output
            mathematica_data.push_back({1, current_max_f_lambda});
        }
    }

    // --- Heuristic Iteration ---
    for (int n = start_n; (recompute_size > 0 ? n < recompute_size : n < N); ++n) {
        cout << "Processing n = " << n << " -> n = " << n + 1 << "..." << endl;

        // Clear G' cache at the start of each iteration to prevent memory growth
        clear_g_prime_cache();

        // 1. Candidate Generation Phase (Size n+1)
        PartitionSet all_unique_candidates_for_n_plus_1;

        // --- Generation from pool_n (Size n -> n+1) ---
        PartitionSet k0_candidates_from_n;
        cout << "  Generating initial (k=0, n->n+1) candidates from " << pool_n.size() << " partitions in pool_n..." << endl;
        for (const auto& scored_p_n : pool_n) {
            const Partition& p_n = scored_p_n.second;
            if (!is_in_subgraph_G_prime(p_n)) {
                cerr << "Warning: Pool partition " << partition_to_string(p_n) << " is not in G'. Skipping initial candidate generation from it." << endl;
                continue;
            }

            vector<Partition> generated_next = add_box(p_n);
            for (const auto& cand : generated_next) {
                if (is_in_subgraph_G_prime(cand)) {
                    k0_candidates_from_n.insert(cand);
                }
            }
        }
        cout << "  Found " << k0_candidates_from_n.size() << " unique k=0 candidates (from n) in G'." << endl;
        all_unique_candidates_for_n_plus_1.insert(k0_candidates_from_n.begin(), k0_candidates_from_n.end());

        // Generate Shaken Candidates (k=1 to MAX_SHAKE_K) from pool_n
        cout << "  Generating shaken (k>0, n->n+1) candidates from k=0 set..." << endl;
        for (int shake_k = 1; shake_k <= MAX_SHAKE_K; ++shake_k) {
            cout << "    Generating for exact shake k=" << shake_k << " (from n source)..." << endl;
            PartitionSet k_shaken_candidates_this_level;
            int initial_cand_count = 0;

            #pragma omp parallel for schedule(dynamic)
            for (size_t i = 0; i < k0_candidates_from_n.size(); ++i) {
                const auto& initial_cand = *(std::next(k0_candidates_from_n.begin(), i));
                PartitionSet shaken = generate_shaken_candidates(initial_cand, shake_k);

                #pragma omp critical
                {
                    k_shaken_candidates_this_level.insert(shaken.begin(), shaken.end());
                    // Progress reporting within the loop
                    initial_cand_count++;
                    if (initial_cand_count % 100 == 0) {
                        cout << "      Shaken " << initial_cand_count << "/" << k0_candidates_from_n.size()
                             << " initial candidates for k=" << shake_k << " (n source)" << endl;
                    }
                }
            }

            size_t before_insert_size = all_unique_candidates_for_n_plus_1.size();
            all_unique_candidates_for_n_plus_1.insert(k_shaken_candidates_this_level.begin(), k_shaken_candidates_this_level.end());
            size_t added_count = all_unique_candidates_for_n_plus_1.size() - before_insert_size;

            cout << "    Found " << k_shaken_candidates_this_level.size() << " raw candidates for k=" << shake_k << " (n source)"
                 << ", added " << added_count << " new unique candidates to the total pool." << endl;
        }
        cout << "  Candidate generation from pool_n complete." << endl;

        // --- Generation from pool_n_minus_1 (Size n-1 -> n+1) ---
        if (n >= 2) { // Only run if pool_n_minus_1 is meaningful
            PartitionSet k0_candidates_from_n_minus_1;
            cout << "  Generating initial (k=0, n-1->n+1) candidates from " << pool_n_minus_1.size() << " partitions in pool_n_minus_1..." << endl;
            for (const auto& scored_p_n_minus_1 : pool_n_minus_1) {
                const Partition& p_n_minus_1 = scored_p_n_minus_1.second;
                if (!is_in_subgraph_G_prime(p_n_minus_1)) continue; // Check base partition

                PartitionSet two_box_candidates = add_two_boxes(p_n_minus_1);
                for (const auto& cand : two_box_candidates) {
                    if (is_in_subgraph_G_prime(cand)) {
                        k0_candidates_from_n_minus_1.insert(cand);
                    }
                }
            }
            cout << "  Found " << k0_candidates_from_n_minus_1.size() << " unique k=0 candidates (from n-1) in G'." << endl;
            size_t before_insert_n1_k0 = all_unique_candidates_for_n_plus_1.size();
            all_unique_candidates_for_n_plus_1.insert(k0_candidates_from_n_minus_1.begin(), k0_candidates_from_n_minus_1.end());
            cout << "    Added " << all_unique_candidates_for_n_plus_1.size() - before_insert_n1_k0 << " new unique candidates from n-1 (k=0) source." << endl;

            cout << "  Generating shaken (k>0, n-1->n+1) candidates from k=0 (n-1) set..." << endl;
            for (int shake_k = 1; shake_k <= MAX_SHAKE_K; ++shake_k) {
                cout << "    Generating for exact shake k=" << shake_k << " (from n-1 source)..." << endl;
                PartitionSet k_shaken_candidates_n1_source;

                #pragma omp parallel for schedule(dynamic)
                for (size_t i = 0; i < k0_candidates_from_n_minus_1.size(); ++i) {
                    const auto& initial_cand = *(std::next(k0_candidates_from_n_minus_1.begin(), i));
                    PartitionSet shaken = generate_shaken_candidates(initial_cand, shake_k);

                    #pragma omp critical
                    {
                        k_shaken_candidates_n1_source.insert(shaken.begin(), shaken.end());
                    }
                }

                size_t before_insert_n1_k = all_unique_candidates_for_n_plus_1.size();
                all_unique_candidates_for_n_plus_1.insert(k_shaken_candidates_n1_source.begin(), k_shaken_candidates_n1_source.end());
                cout << "    Found " << k_shaken_candidates_n1_source.size() << " raw candidates (k=" << shake_k << ", n-1 src)"
                     << ", added " << all_unique_candidates_for_n_plus_1.size() - before_insert_n1_k << " new unique candidates." << endl;
            }
            cout << "  Candidate generation from pool_n_minus_1 complete." << endl;
        } else {
            cout << "  Skipping candidate generation from n-1 pool (n=" << n << ")." << endl;
        }
        // --- End Generation from pool_n_minus_1 ---

        cout << "  Total unique candidates generated for n = " << n + 1 << " from ALL sources: " << all_unique_candidates_for_n_plus_1.size() << endl;

        // 2. Evaluation Phase (Size n+1)
        vector<ScoredPartition> evaluated_candidates_for_n_plus_1;
        evaluated_candidates_for_n_plus_1.reserve(all_unique_candidates_for_n_plus_1.size());
        std::mutex eval_mutex; // Mutex for thread-safe push_back to vector
        long long evaluated_count = 0;

        cout << "  Evaluating " << all_unique_candidates_for_n_plus_1.size() << " total unique candidates for n = " << n + 1 << "..." << endl;

        #pragma omp parallel for schedule(dynamic)
        for (size_t i = 0; i < all_unique_candidates_for_n_plus_1.size(); ++i) {
            const auto& cand = *(std::next(all_unique_candidates_for_n_plus_1.begin(), i));
            BigInt f_cand = countSYT_gmp(cand);

            if (f_cand != -1) { // Check for errors from countSYT_gmp
                // Add result to shared vector under lock
                std::lock_guard<std::mutex> lock(eval_mutex);
                evaluated_candidates_for_n_plus_1.push_back({f_cand, cand});
            }

            // Thread-safe progress reporting
            long long current_eval_count;
            #pragma omp atomic update
            evaluated_count++;
            current_eval_count = evaluated_count; // Read atomic value

            if (current_eval_count % 1000 == 0) { // Report every 1000 evaluations
                #pragma omp critical
                {
                    cout << "    Evaluated " << current_eval_count << "/" << all_unique_candidates_for_n_plus_1.size() << " candidates..." << endl;
                }
            }
        }

        cout << "  Evaluation complete. Found " << evaluated_candidates_for_n_plus_1.size() << " valid scored candidates." << endl;

        // Check if any candidates were successfully evaluated
        if (evaluated_candidates_for_n_plus_1.empty()) {
            cout << "No valid candidates could be evaluated for n = " << n + 1 << ". Stopping." << endl;
            // Handle file output for this case (e.g., write N/A)
            outfile << "\n--- Size " << n + 1 << " ---" << endl;
            outfile << "Max f^lambda: N/A (No valid candidates found/evaluated)" << endl;
            break; // Exit the main loop for n
        }

        // 3. Selection Phase (Update Pool and Best for Output)
        // Sort evaluated candidates by score (descending)
        cout << "  Sorting evaluated candidates..." << endl;
        std::sort(evaluated_candidates_for_n_plus_1.begin(), evaluated_candidates_for_n_plus_1.end(),
                  [](const ScoredPartition& a, const ScoredPartition& b) {
                      // Primary sort: score descending
                      if (a.first != b.first) {
                          return a.first > b.first;
                      }
                      // Secondary sort: partition lexicographical (optional, for consistency)
                      return a.second < b.second;
                  });

        // Determine overall max for output
        BigInt next_max_f_lambda = evaluated_candidates_for_n_plus_1[0].first;
        vector<Partition> next_overall_best_partitions;
        for(const auto& scored_cand : evaluated_candidates_for_n_plus_1) {
            if (scored_cand.first == next_max_f_lambda) {
                next_overall_best_partitions.push_back(scored_cand.second);
            } else {
                break; // Scores are sorted, no need to check further
            }
        }

        cout << "  Overall max f^lambda for n = " << n + 1 << " is " << next_max_f_lambda
             << " achieved by " << next_overall_best_partitions.size() << " partitions." << endl;

        // Create the pool for the next iteration (n+1 -> n+2)
        vector<ScoredPartition> next_top_partitions_pool;
        PartitionSet added_to_pool_set; // Track unique partitions added to the pool
        BigInt cutoff_score = -1; // Score of the last partition added if limit is reached

        cout << "  Selecting top partitions for the next pool (limit " << STORED_MAX_PARTITIONS_N << ")..." << endl;
        for (const auto& scored_cand : evaluated_candidates_for_n_plus_1) {
            bool should_add = false;
            if (next_top_partitions_pool.size() < STORED_MAX_PARTITIONS_N) {
                // Add if pool is not full and partition is unique
                should_add = true;
            } else {
                // Pool is full, check if current score is >= cutoff score (handle ties)
                if (cutoff_score == -1) { // Set cutoff score first time limit is hit
                    cutoff_score = next_top_partitions_pool.back().first;
                }
                if (scored_cand.first >= cutoff_score) {
                    should_add = true;
                } else {
                    // Score is lower than cutoff, and pool is full. Stop adding.
                    break;
                }
            }

            // Add the partition if it meets criteria and is unique
            if (should_add) {
                // Use emplace for potential efficiency
                auto insert_result = added_to_pool_set.insert(scored_cand.second);
                if (insert_result.second) { // Check if insertion happened (i.e., was unique)
                    next_top_partitions_pool.push_back(scored_cand);
                    // Update cutoff score if we just reached the limit
                    if (next_top_partitions_pool.size() == STORED_MAX_PARTITIONS_N) {
                        cutoff_score = scored_cand.first;
                    }
                }
            }
        }

        cout << "  Selected " << next_top_partitions_pool.size() << " partitions for the next iteration's pool." << endl;

        // Update pools for the next iteration (n+1 -> n+2)
        pool_n_minus_1 = std::move(pool_n); // The current n pool becomes the next n-1 pool
        pool_n = std::move(next_top_partitions_pool); // The new n+1 pool becomes the next n pool

        // Apply size limit to pool_n_minus_1 if needed
        if (pool_n_minus_1.size() > STORED_MAX_PARTITIONS_N_MINUS_1) {
            // Sort by score (should be sorted already, but just to be safe)
            std::sort(pool_n_minus_1.begin(), pool_n_minus_1.end(),
                [](const ScoredPartition& a, const ScoredPartition& b) {
                    // Primary sort: score descending
                    if (a.first != b.first) {
                        return a.first > b.first;
                    }
                    // Secondary sort: partition lexicographical (optional, for consistency)
                    return a.second < b.second;
                });

            BigInt cutoff_score_n1 = pool_n_minus_1[STORED_MAX_PARTITIONS_N_MINUS_1 - 1].first;

            // If there are ties at the cutoff, we might slightly exceed the limit
            pool_n_minus_1.erase(
                std::remove_if(pool_n_minus_1.begin(), pool_n_minus_1.end(),
                              [&](const ScoredPartition& sp){ return sp.first < cutoff_score_n1; }),
                pool_n_minus_1.end());

            cout << "  Trimmed pool_n_minus_1 to size " << pool_n_minus_1.size()
                 << " (limit " << STORED_MAX_PARTITIONS_N_MINUS_1 << ") for next iteration." << endl;
        }

        overall_best_partitions_for_n = std::move(next_overall_best_partitions); // Update for output
        current_max_f_lambda = next_max_f_lambda; // Update for output

        // 4. Store for Mathematica output
        mathematica_data.push_back({n + 1, current_max_f_lambda});

        // 5. Write Results to File
        outfile << "\n--- Size " << n + 1 << " ---" << endl;
        int count = overall_best_partitions_for_n.size();
        if (count == 0) {
            outfile << "Max f^lambda: 0 (No partitions found achieving max within G')" << endl;
            cout << "Warning: No best partitions found for n = " << n+1 << " within G'." << endl;
        } else {
            outfile << "Max f^lambda: " << current_max_f_lambda << " (achieved by " << count << " partition" << (count == 1 ? "" : "s") << " in G')" << endl;
            outfile << "Partitions achieving maximum: ";
            std::sort(overall_best_partitions_for_n.begin(), overall_best_partitions_for_n.end()); // Sort for consistent output
            for (size_t i = 0; i < overall_best_partitions_for_n.size(); ++i) {
                outfile << partition_to_string(overall_best_partitions_for_n[i]) << (i == overall_best_partitions_for_n.size() - 1 ? "" : ", ");
            }
            outfile << endl;
        }

        // Basic progress update to console
        cout << "  Found max f^lambda = " << current_max_f_lambda << " for n = " << n+1 << " within G'." << endl;

        // Print current time to stderr
        auto now = std::chrono::system_clock::now();
        std::time_t current_time = std::chrono::system_clock::to_time_t(now);
        cerr << "  Current time after processing n = " << n+1 << ": "
             << std::put_time(std::localtime(&current_time), "%Y-%m-%d %H:%M:%S") << endl;

    } // End loop for n

    // Close the output file if it's still open
    if (outfile.is_open()) {
        outfile.close();
    }

    // If we're doing a specific size recomputation, now we need to update the file
    if (recompute_size > 0) {
        cout << "Recomputation for size " << recompute_size << " complete." << endl;
        cout << "Updating file with new data for size " << recompute_size << "..." << endl;

        // Read the entire file content
        std::ifstream infile("heuristic_results.txt");
        if (!infile) {
            cerr << "Error: Could not open file heuristic_results.txt for reading." << endl;
            return 1;
        }

        std::vector<string> lines;
        string line;
        while (std::getline(infile, line)) {
            lines.push_back(line);
        }
        infile.close();

        // Find where to insert the updated size data
        size_t insert_index = lines.size(); // By default, append at the end
        bool found_size_marker = false;
        bool found_next_size = false;

        // Find the lines for the size we want to update
        for (size_t i = 0; i < lines.size(); i++) {
            if (lines[i].find("--- Size " + std::to_string(recompute_size) + " ---") != string::npos) {
                found_size_marker = true;
                insert_index = i;
                // Now look for the next size marker or the end of file
                for (size_t j = i + 1; j < lines.size(); j++) {
                    if (lines[j].find("--- Size ") != string::npos) {
                        found_next_size = true;
                        break;
                    }
                }
                break;
            }
        }

        // Prepare the new content for this size
        std::vector<string> new_content;
        new_content.push_back("--- Size " + std::to_string(recompute_size) + " ---");

        // Find the new data for this size
        bool found_new_data = false;
        for (size_t i = 0; i < size_to_partitions.size(); i++) {
            if (size_to_partitions[i].first == recompute_size) {
                const auto& parts = size_to_partitions[i].second;
                BigInt max_f = 0;

                // Find the corresponding max_f value
                for (const auto& data : mathematica_data) {
                    if (data.first == recompute_size) {
                        max_f = data.second;
                        found_new_data = true;
                        break;
                    }
                }

                if (found_new_data) {
                    if (parts.empty()) {
                        new_content.push_back("Max f^lambda: N/A (No candidates found within G' constraints)");
                    } else {
                        new_content.push_back("Max f^lambda: " + max_f.get_str() + " (achieved by " + std::to_string(parts.size()) + " partition" + (parts.size() == 1 ? "" : "s") + " in G')");
                        string partitions_line = "Partitions achieving maximum: ";
                        for (size_t j = 0; j < parts.size(); ++j) {
                            partitions_line += partition_to_string(parts[j]) + (j == parts.size() - 1 ? "" : ", ");
                        }
                        new_content.push_back(partitions_line);
                    }
                }
                break;
            }
        }

        // If no new data was found, something went wrong
        if (!found_new_data) {
            cerr << "Error: No new data found for size " << recompute_size << " after recomputation." << endl;
            return 1;
        }

        // Open file for writing
        std::ofstream update_file("heuristic_results.txt");
        if (!update_file) {
            cerr << "Error: Could not open file heuristic_results.txt for writing." << endl;
            return 1;
        }

        // Write the content with the updated section
        if (found_size_marker) {
            // Write everything before the size marker
            for (size_t i = 0; i < insert_index; i++) {
                update_file << lines[i] << endl;
            }

            // Write the new content
            for (const auto& content_line : new_content) {
                update_file << content_line << endl;
            }

            // Skip over the current size lines until we find the next size marker
            bool skip_current_size = false;
            bool found_next_marker = false;
            for (size_t i = insert_index; i < lines.size(); i++) {
                if (!skip_current_size && lines[i].find("--- Size " + std::to_string(recompute_size) + " ---") != string::npos) {
                    // Found the current size marker - skip it and subsequent lines until next size
                    skip_current_size = true;
                    continue;
                }

                if (skip_current_size && !found_next_marker && lines[i].find("--- Size ") != string::npos) {
                    // Found the next size marker
                    found_next_marker = true;
                }

                if (!skip_current_size || found_next_marker) {
                    // Either we're before the current size or after finding the next size marker
                    update_file << lines[i] << endl;
                }
            }
        } else {
            // Size not found, so write the existing content and append the new size
            for (const auto& existing_line : lines) {
                update_file << existing_line << endl;
            }

            // Add a blank line before the new content if the file doesn't end with one
            if (!lines.empty() && !lines.back().empty()) {
                update_file << endl;
            }

            // Write the new content
            for (const auto& content_line : new_content) {
                update_file << content_line << endl;
            }
        }

        update_file.close();
        cout << "Updated file with new data for size " << recompute_size << endl;
    } else {
        cout << "\nHeuristic search complete. Results saved to heuristic_results.txt" << endl;
    }

    // Print Mathematica format output
    cout << "\nMathematica format output:" << endl;
    cout << "MM := {";
    for (size_t i = 0; i < mathematica_data.size(); ++i) {
        cout << "{" << mathematica_data[i].first << ", " << mathematica_data[i].second << "}";
        if (i < mathematica_data.size() - 1) {
            cout << ", ";
        }
    }
    cout << "}" << endl;

    return 0;
}


// --- Helper Function Implementations ---

string partition_to_string(const Partition& p) {
    std::stringstream ss;
    ss << "[";
    for (size_t i = 0; i < p.size(); ++i) {
        ss << p[i] << (i == p.size() - 1 ? "" : ", ");
    }
    ss << "]";
    return ss.str();
}

vector<Partition> add_box(const Partition& mu) {
    vector<Partition> next_partitions;
    PartitionSet generated_set;
    if (!is_valid_partition(mu)) return next_partitions; // Ensure input is valid

    // Case 1: Add to existing row
    for (size_t i = 0; i < mu.size(); ++i) {
        if (i == 0 || mu[i] < mu[i - 1]) {
            Partition lambda = mu;
            lambda[i]++;
            if (is_valid_partition(lambda)) { // Double check validity
                generated_set.insert(lambda);
            }
        }
    }
    // Case 2: Add new row
    Partition lambda_new_row = mu;
    lambda_new_row.push_back(1);
    if (is_valid_partition(lambda_new_row)) {
        generated_set.insert(lambda_new_row);
    }
    next_partitions.assign(generated_set.begin(), generated_set.end());
    return next_partitions;
}

// Generates partitions of size |p|+2 by adding two boxes.
PartitionSet add_two_boxes(const Partition& p_n_minus_1) {
    PartitionSet result_n_plus_1_set;
    if (!is_valid_partition(p_n_minus_1)) return result_n_plus_1_set;

    // First box addition
    vector<Partition> intermediates_n = add_box(p_n_minus_1);

    for (const auto& p_n : intermediates_n) {
        // Second box addition
        if (!is_valid_partition(p_n)) continue; // Should be valid, but double-check
        vector<Partition> candidates_n_plus_1 = add_box(p_n);
        for (const auto& p_n_plus_1 : candidates_n_plus_1) {
            if (is_valid_partition(p_n_plus_1)) { // Final validity check
                result_n_plus_1_set.insert(p_n_plus_1);
            }
        }
    }
    return result_n_plus_1_set;
}

// Generate partitions of size |lambda|-1 by removing one outer corner box
vector<Partition> remove_box(const Partition& lambda) {
    vector<Partition> prev_partitions;
    PartitionSet generated_set;
     if (!is_valid_partition(lambda)) return prev_partitions;

    for (size_t i = 0; i < lambda.size(); ++i) {
        unsigned int len = lambda[i];
        if (len == 0) continue; // Skip zero parts if any snuck in

        // Check if box (i, len-1) is an outer corner (removable)
        // Condition: It's the last box in its row AND
        //            (it's the last row OR the row below is shorter)
        bool is_outer_corner = ( (i + 1 == lambda.size()) || (lambda[i+1] < len) );

        if (is_outer_corner) {
            Partition mu = lambda;
            mu[i]--;
            // Remove row if it becomes empty
            if (mu[i] == 0) {
                mu.erase(mu.begin() + i);
            }
            // Check if the result is still a valid partition
            if (is_valid_partition(mu)) {
                 generated_set.insert(mu);
            }
        }
    }
    prev_partitions.assign(generated_set.begin(), generated_set.end());
    return prev_partitions;
}

// Generate additional candidates by "shaking" (exactly k remove/add steps)
// Returns only partitions of the same size as lambda_start that are in G'
PartitionSet generate_shaken_candidates(const Partition& lambda_start, int exact_k) {
    PartitionSet final_shaken_partitions_Gprime;
    if (!is_in_subgraph_G_prime(lambda_start)) {
        return final_shaken_partitions_Gprime; // Start must be in G'
    }

    PartitionSet current_level_partitions;
    current_level_partitions.insert(lambda_start);
    PartitionSet all_reachable_partitions; // Keep track of all visited partitions during shake
    all_reachable_partitions.insert(lambda_start);

    // Perform exactly 'exact_k' levels of shaking
    for (int k = 1; k <= exact_k; ++k) {
        PartitionSet next_level_partitions;
        if (current_level_partitions.empty()) break; // Stop if no more partitions to explore

        int processed_count = 0;
        for (const auto& p : current_level_partitions) {
            processed_count++;
            // Remove one box
            vector<Partition> removed = remove_box(p);
            for (const auto& r : removed) {
                // Add one box
                vector<Partition> added = add_box(r);
                for (const auto& a : added) {
                    // Check if the result 'a' is valid, in G', and not seen before in *this* k-shake process
                    if (all_reachable_partitions.find(a) == all_reachable_partitions.end()) {
                         if (is_in_subgraph_G_prime(a)) {
                             next_level_partitions.insert(a);
                             // Only add to final result if we're at the exact_k level
                             if (k == exact_k) {
                                 final_shaken_partitions_Gprime.insert(a);
                             }
                         }
                        all_reachable_partitions.insert(a); // Mark as visited for this shake sequence
                    }
                }
            }
        }
        current_level_partitions = next_level_partitions; // Move to the next level
    }

    // The final set contains only partitions in G' reachable in exactly exact_k steps,
    // EXCLUDING the starting partition itself (as it's an initial candidate).
    final_shaken_partitions_Gprime.erase(lambda_start);

    return final_shaken_partitions_Gprime;
}


bool is_valid_partition(const Partition& p) {
    if (p.empty()) return true;
    if (p[0] == 0) return false;
    for (size_t i = 1; i < p.size(); ++i) {
        if (p[i] == 0) return false;
        if (p[i] > p[i-1]) return false;
    }
    return true;
}

Partition get_base_symmetric_subdiagram(const Partition& p) {
     // Optimization: If partition is empty or first element is 0, return empty.
     if (p.empty() || p[0] == 0) {
         return Partition();
     }

     // Calculate conjugate partition more carefully
     Partition p_conj;
     if (!p.empty()) {
         p_conj.resize(p[0], 0); // Max possible length is p[0]
         for (unsigned int part_len : p) {
             for (size_t i = 0; i < part_len; ++i) {
                 // Ensure index is within bounds before incrementing
                 if (i < p_conj.size()) {
                     p_conj[i]++;
                 } else {
                    // This case suggests an issue, maybe the initial resize wasn't enough
                    // or the input partition 'p' might be malformed.
                    // For safety, let's break or log an error.
                     // cerr << "Warning: Index out of bounds during conjugate calculation for " << partition_to_string(p) << endl;
                     break; // Stop processing this part_len
                 }
             }
         }
          // Trim trailing zeros from conjugate
          while (!p_conj.empty() && p_conj.back() == 0) {
              p_conj.pop_back();
          }
     }


     Partition lambda_sym;
     size_t max_k = min(p.size(), p_conj.size());
     for (size_t k = 0; k < max_k; ++k) {
         unsigned int side = min(p[k], p_conj[k]);
         if (side > 0 && (lambda_sym.empty() || side <= lambda_sym.back())) {
              lambda_sym.push_back(side);
         } else {
             // If side is 0 or breaks non-increasing property, stop.
             break;
         }
     }

     // Final check to ensure lambda_sym is valid itself
     if (!is_valid_partition(lambda_sym)) {
        // This might happen if min(p[k], p_conj[k]) calculation leads to invalid sequence
        // Try to truncate further? Or return empty? Returning empty might be safer.
        // cerr << "Warning: Calculated base symmetric subdiagram " << partition_to_string(lambda_sym) << " is invalid for " << partition_to_string(p) << endl;
         return Partition();
     }


     return lambda_sym;
}

// Cache for is_in_subgraph_G_prime results
static std::map<Partition, bool> g_prime_cache;
static std::mutex g_prime_cache_mutex; // Mutex to protect the cache

// Function to clear the G' cache
void clear_g_prime_cache() {
    size_t cache_size;
    {
        std::lock_guard<std::mutex> lock(g_prime_cache_mutex);
        cache_size = g_prime_cache.size();
        g_prime_cache.clear();
    }

    if (cache_size > 0) {
        cout << "  Cleared G' cache containing " << cache_size << " entries." << endl;
    }
}

bool is_in_subgraph_G_prime(const Partition& p) {
    // Check cache first (use lock guard for thread safety)
    {
        std::lock_guard<std::mutex> lock(g_prime_cache_mutex);
        auto it = g_prime_cache.find(p);
        if (it != g_prime_cache.end()) {
            return it->second;
        }
    } // Lock released here

    // Original computation logic
    bool result = false; // Default to false

    if (!is_valid_partition(p)) {
        result = false;
    } else if (p.empty()) {
        result = true;
    } else {
        Partition lambda_sym = get_base_symmetric_subdiagram(p);

        std::map<int, int> extra_boxes_in_row; // Map row_index -> count
        size_t sym_idx = 0; // Index for lambda_sym
        bool conditions_met = true; // Assume true initially

        for (size_t i = 0; i < p.size(); ++i) { // i is 0-based row index
            unsigned int p_row_len = p[i];
            unsigned int sym_row_len = (sym_idx < lambda_sym.size()) ? lambda_sym[sym_idx] : 0;

            if (p_row_len > sym_row_len) {
                // This row extends beyond the symmetric core
                for (size_t j = sym_row_len; j < p_row_len; ++j) { // j is 0-based col index
                    // Check if box (i+1, j+1) is strictly below diagonal y=x
                    if (!((i + 1) > (j + 1))) {
                        conditions_met = false; // Condition 1 failed
                        break; // Exit inner loop
                    }
                    // Check row constraint
                    extra_boxes_in_row[i]++;
                    if (extra_boxes_in_row[i] > 1) {
                        conditions_met = false; // Condition 2 failed
                        break; // Exit inner loop
                    }
                }
            }

            if (!conditions_met) break; // Exit outer loop

            // Logic to advance sym_idx correctly:
            // Advance if we 'consumed' a row from the symmetric diagram,
            // even if that row had length 0 in the symmetric diagram but >0 in p.
            if (sym_idx < lambda_sym.size()) {
                sym_idx++;
            }
            // If p has more rows than lambda_sym, these extra rows must be checked.
            // The loops handle this naturally. If p[i] > sym_row_len (which is 0 here),
            // the inner loop checks the boxes.
        }

        result = conditions_met; // Final result of computation
    }

    // Store result in cache (use lock guard)
    {
        std::lock_guard<std::mutex> lock(g_prime_cache_mutex);
        g_prime_cache[p] = result;
    } // Lock released here

    return result;
}

long long hookLength(const Partition& partition, int r, int c) {
     if (r < 0 || r >= partition.size() || c < 0 || c >= partition[r]) {
        throw std::out_of_range("hookLength: indices (" + std::to_string(r) + "," + std::to_string(c) + ") out of range for partition " + partition_to_string(partition));
     }
     long long arm = static_cast<long long>(partition[r]) - (c + 1);
     long long leg = 0;
     for (size_t i = r + 1; i < partition.size(); ++i) {
         if (partition[i] > c) { leg++; } else { break; }
     }
     return arm + leg + 1;
}

BigInt countSYT_gmp(const Partition& partition) {
    unsigned long n_ul = 0;
    if (partition.empty()) return 1;
    for (unsigned int part : partition) {
        if (part == 0) { cerr << "Error (countSYT_gmp): Partition " << partition_to_string(partition) << " contains zero part.\n"; return -1; }
        n_ul += part;
    }
    if (n_ul == 0 && !partition.empty()) { cerr << "Error (countSYT_gmp): Non-empty partition " << partition_to_string(partition) << " has size 0.\n"; return -1; }

    BigInt n_factorial;
    mpz_fac_ui(n_factorial.get_mpz_t(), n_ul);

    BigInt product_hook_lengths = 1;
    try {
        for (int r = 0; r < partition.size(); ++r) {
            for (int c = 0; c < partition[r]; ++c) {
                long long hl = hookLength(partition, r, c);
                if (hl <= 0) { cerr << "Error (countSYT_gmp): Non-positive hook length (" << hl << ") for cell (" << r << "," << c << ") in partition " << partition_to_string(partition) << ".\n"; return -1; }
                product_hook_lengths *= BigInt(std::to_string(hl)); // Use GMP overloaded operator
            }
        }
    } catch (const std::out_of_range& oor) { cerr << "Error (countSYT_gmp): " << oor.what() << endl; return -1; }

    if (product_hook_lengths == 0) { cerr << "Error (countSYT_gmp): Product of hook lengths is zero for partition " << partition_to_string(partition) << ".\n"; return -1; }

    BigInt result;
    if (mpz_divisible_p(n_factorial.get_mpz_t(), product_hook_lengths.get_mpz_t())) {
        mpz_divexact(result.get_mpz_t(), n_factorial.get_mpz_t(), product_hook_lengths.get_mpz_t());
    } else { cerr << "Error (countSYT_gmp): n! (" << n_ul << "!) not divisible by product of hooks for partition " << partition_to_string(partition) << ".\n"; return -1; }
    return result;
}
